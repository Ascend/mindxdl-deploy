apiVersion: v1
kind: ConfigMap
metadata:
  name: rings-config-training-toolkit     # The value of JobName must be the same as the name attribute of the following job. The prefix rings-config- cannot be modified.
  namespace: vcjob                      # Select a proper namespace based on the site requirements. (The namespaces of ConfigMap and Job must be the same. In addition, if the tjm component of MindX-add exists, the vcjob namespace cannot be used.)
  labels:
    ring-controller.atlas: ascend-910
data:
  hccl.json: |
    {
        "status":"initializing"
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fault-config-training-toolkit     # The value of JobName must be the same as the name attribute of the following job. The prefix fault-config- cannot be modified.
  namespace: vcjob                      # Select a proper namespace based on the site requirements. (The namespaces of ConfigMap and Job must be the same. In addition, if the tjm component of MindX-add exists, the vcjob namespace cannot be used.)
data:
  fault-npus: |
    {
        "status":"initializing"
    }
  checkCode: ""
---
apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: training-toolkit                  # The value must be consistent with the name of ConfigMap.
  namespace: vcjob                      # Select a proper namespace based on the site requirements. (The namespaces of ConfigMap and Job must be the same. In addition, if the tjm component of MindX-add exists, the vcjob namespace cannot be used.)
  labels:
    ring-controller.atlas: ascend-910   # The HCCL-Controller distinguishes Ascend 910 and other processors based on this label.
    fault-scheduling: "force"
spec:
  minAvailable: 1                       # The value of minAvailable is 1 in a single-node scenario and N in an N-node distributed scenario.
  schedulerName: volcano                # Use the Volcano scheduler to schedule jobs.
  policies:
    - event: PodEvicted
      action: RestartJob
  plugins:
    ssh: []
    env: []
    svc: []
  maxRetry: 3
  queue: default
  tasks:
  - name: "test-ms"
    replicas: 1                         # The value of replicas is 1 in a single-node scenario and N in an N-node scenario. The number of NPUs in the requests field is 8 in an N-node scenario.
    template:
      metadata:
        labels:
          app: mindspore
          ring-controller.atlas: ascend-910
      spec:
        hostNetwork: true
        terminationGracePeriodSeconds: 900
        containers:
        - image: all_platform_ssh_x86:rc3.b100         # Training framework image, which can be modified.
          imagePullPolicy: IfNotPresent
          name: mindspore
          env:
          - name: training-toolkit        # The value must be consistent with the value of JobName.
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: XDL_IP                # IP address of the physical node, which is used to identify the node where the pod is running
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: INCLUSTER_FLAG                # whether training task run on multi nodes. If yes, set value to True, otherwise False
            value: "True"
          command: ["/bin/bash", "-c", "training-toolkit --test ms"] # Commands for running the training script. Ensure that the involved commands and paths exist on Docker.
          resources:
            requests:
              huawei.com/Ascend910: 1                                                # Number of required NPUs. The maximum value is 8. You can add lines below to configure resources such as memory and CPU.
            limits:
              huawei.com/Ascend910: 1                                                # The value must be consistent with that in requests.
          volumeMounts:
          - name: ascend-910-config
            mountPath: /user/serverid/devindex/config
          - name: fault-config
            mountPath: /user/restore/fault/config
          - name: code
            mountPath: /job/code/
          - name: data
            mountPath: /job/data
          - name: ascend-driver
            mountPath: /usr/local/Ascend/driver
          - name: ascend-add-ons
            mountPath: /usr/local/Ascend/add-ons
          - name: log-mindxtrainingtoolkit
            mountPath: /var/log/mindx-dl/training_toolkit
          - name: log-mindxelastic
            mountPath: /var/log/mindx-dl/elastic
          - name: localtime
            mountPath: /etc/localtime
          - name: dshm
            mountPath: /dev/shm
        nodeSelector:
          host-arch: huawei-x86                                # Configure the label based on the actual job.
        volumes:
        - name: ascend-910-config
          configMap:
            name: rings-config-training-toolkit                  # Correspond to the ConfigMap name above.
        - name: fault-config
          configMap:
            name: fault-config-training-toolkit                  # Correspond to the ConfigMap name above.
        - name: code
          nfs:
            server: 127.0.0.1                                  # IP address of the NFS server. In this example, the shared path is /data/atlas_dls/.
            path: "/data/atlas_dls/code"                       # Configure the path of the training script.
        - name: data
          nfs:
            server: 127.0.0.1
            path: "/data/atlas_dls/public/dataset"  # Configure the path of the training set.
        - name: ascend-driver
          hostPath:
            path: /usr/local/Ascend/driver                     # Configure the NPU driver and mount it to Docker.
        - name: ascend-add-ons
          hostPath:
            path: /usr/local/Ascend/add-ons                    # Configure the add-ons driver of the NPU and mount it to Docker.
        - name: log-mindxtrainingtoolkit
          hostPath:
            path: /var/log/mindx-dl/training_toolkit                    # Configure the path of log
            type: Directory
        - name: log-mindxelastic
          hostPath:
            path: /var/log/mindx-dl/elastic                    # Configure the path of log
            type: Directory
        - name: localtime
          hostPath:
            path: /etc/localtime                               # Configure the Docker time.
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
        restartPolicy: OnFailure
